target_default: 1_format

packages:
  - zeallot
  - readr
  - yaml
  - googledrive
  - scipiper
  - dplyr
  - feather

sources:
  - lib/src/utils.R
  - 1_format/src/format_tasks.R
  - 1_format/src/calculate_priority_lakes.R

targets:
  1_format:
    depends:
      - 1_format/log/1_format_tasks.ind

  # read and subset the NN settings
  settings:
    command: yaml.load_file('lib/cfg/settings.yml')
  combine_cfg:
    command: settings[I(c('min_obs_per_depth', 'min_obs_per_date'))]
  format_cfg:
    command: settings[I(c('structure'))]
  split_scale_cfg:
    command: settings[I(c('dev_frac', 'test_frac'))]
  glm_yeti_path_cfg:
    command: settings[I(c('glm_yeti_path'))]


  #### retrieve files deposited in our Drive from other pipelines ####

  # The following gd_get calls assume that data files from previous pipelines
  # have been copied from pipelines 1 and 2 to this pipeline's Drive folder,
  # and that their respective indicator files have been copied to this git repo:

  # temperature observations from pipeline #1
  1_format/in/merged_temp_data_daily.feather:
    command: gd_get(ind_file = '1_format/in/merged_temp_data_daily.feather.ind')

  # NLDAS-NHD crosswalk from pipeline #2 (master NHD lake list with names and corresponding NLDAS tilenames)
  1_format/in/feature_nldas_coords.rds:
    command: gd_get(ind_file = '1_format/in/feature_nldas_coords.rds.ind')


  #### identify priority lakes ####

  priority_lakes_by_choice:
   command: get_site_ids(file = '1_format/in/pipeline_3_lakes.csv')

  priority_lakes_by_data:
    command: calc_priority_lakes(
      temp_dat_ind = '1_format/in/merged_temp_data_daily.feather.ind',
      n_min = 2000,
      n_years = 30,
      years_with_7months = 10,
      years_with_10days = 20,
      n_days = 1000)

  priority_lakes:
    command: combine_priorities(
      priority_lakes_by_choice,
      priority_lakes_by_data,
      nldas_crosswalk_ind = "1_format/in/feature_nldas_coords.rds.ind",
      truncate_lakes_for_dev = I(TRUE))


  #### prepare PGDL data for priority lakes ####

  # The following task plan pulls driver data and GLM outputs from the Yeti
  # project directory, /cxfs/projects/usgs/water/iidd/data-sci/lake-temp.
  #   * From pipeline 1 (lake-temp/driver-data on Yeti):
  #     driver data packaged in cell-specific files, e.g., NLDAS_time[0.346848]_x[335]_y[142].csv
  #   * From pipeline 2 (lake-temp/glm_output on Yeti):
  #     GLM output packaged in lake-specific files, e.g., nhd_13293262_output.nc

  format_data_task_plan:
    command: create_format_task_plan(priority_lakes, ind_dir = I("1_format"))

  1_format_tasks.yml:
    command: create_format_task_makefile(task_plan = format_data_task_plan, makefile = target_name, ind_complete=TRUE)

  1_format/log/1_format_tasks.ind:
    command: loop_tasks(task_plan = format_data_task_plan, task_makefile = '1_format_tasks.yml', num_tries=1)
